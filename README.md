<div align="center">

# üîí IPBlocklist

Threat intelligence aggregator that collects, processes, and serves IP reputation data from 128 security feeds into an optimized binary format for fast lookups.

<p align="center">
<img src="https://img.shields.io/github/actions/workflow/status/tn3w/IPBlocklist/aggregate-feeds.yml?label=Build&style=for-the-badge" alt="GitHub Workflow Status">
<img src="https://img.shields.io/badge/dataset-9.1M_entries-blue?style=for-the-badge" alt="Dataset Size">
<img src="https://img.shields.io/badge/IPs-4.4M-green?style=for-the-badge" alt="Individual IPs">
<img src="https://img.shields.io/badge/ranges-4647K-orange?style=for-the-badge" alt="CIDR Ranges">
</p>

<p align="center">
<a href="https://github.com/tn3w/IPBlocklist/releases/latest/download/blocklist.json"><img src="https://img.shields.io/badge/download-blocklist.json_(60MB)-red?style=for-the-badge&logo=download&logoColor=white" alt="Download Threat Data"></a>
</p>

</div>

## üöÄ Key Features

- ‚úÖ Fast IP lookups in <1ms using binary search
- ‚úÖ 9.1M+ IPs and CIDR ranges from 127 threat intelligence feeds
- ‚úÖ Malware C&C servers, botnets, spam networks, compromised hosts
- ‚úÖ VPN providers, Tor nodes, datacenter/hosting ASNs
- ‚úÖ Optimized integer storage for minimal memory footprint
- ‚úÖ Support for both IPv4 and IPv6
- ‚úÖ Automated daily updates via GitHub Actions

## üì• Download & Extract

The dataset is available as a downloadable JSON file.

### Threat Intelligence Data

The threat intelligence dataset is approximately 60MB.

```bash
# Download the file
wget https://github.com/tn3w/IPBlocklist/releases/latest/download/blocklist.json

# Verify the file
ls -lh blocklist.json
```

## üìä Architecture

```
feeds.json ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ> aggregator.py ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ> blocklist.json
  (config)              (processor)              (threat intel)
```

## üìñ Overview

IPBlocklist downloads threat intelligence from multiple sources (malware C&C servers, botnets, spam networks, VPN providers, Tor nodes, etc.) and converts them into a compact, searchable format. IP addresses are stored as integers and CIDR ranges as [start, end] pairs for efficient binary search lookups.

The system uses open-source security feeds configured in feeds.json, which are processed by aggregator.py into a unified blocklist.json file.

## üìÅ Data Models

### feeds.json

Configuration file defining all threat intelligence sources. Each feed is an independent object with complete metadata.

**Structure**: Array of feed objects

```json
[
    {
        "name": "feodotracker",
        "url": "https://feodotracker.abuse.ch/downloads/ipblocklist.txt",
        "description": "Feodo Tracker - Botnet C&C",
        "regex": "^(?![#;/])([0-9a-fA-F:.]+(?:/\\d+)?)",
        "base_score": 1.0,
        "confidence": 0.95,
        "flags": ["is_malware", "is_botnet", "is_c2_server"],
        "categories": ["malware", "botnet"]
    }
]
```

**Required Fields**:

- `name`: Unique identifier for the feed
- `url`: Download URL for the threat list
- `description`: Human-readable description
- `regex`: Pattern to extract IPs/CIDRs from feed content
- `base_score`: Threat severity (0.0-1.0)
- `confidence`: Data reliability (0.0-1.0)
- `flags`: Boolean indicators (is_anycast, is_botnet, is_brute_force, is_c2_server, is_cdn, is_cloud, is_compromised, is_datacenter, is_forum_spammer, is_isp, is_malware, is_mobile, is_phishing, is_proxy, is_scanner, is_spammer, is_tor, is_vpn, is_web_attacker)
- `categories`: Categories for scoring (anonymizer, attacks, botnet, compromised, infrastructure, malware, spam)

**Optional Fields**:

- `provider_name`: VPN/hosting provider name

### datacenter_asns.json

List of Autonomous System Numbers (ASNs) associated with datacenter and hosting providers.

**Structure**: Array of ASN strings

```json
["15169", "16509", "13335", "8075", "14061"]
```

This file is automatically generated when processing the datacenter_asns feed and can be used for O(1) ASN lookups to identify datacenter traffic.

### blocklist.json

Processed output with all IPs converted to integers for fast lookups.

**Structure**: Object with timestamp and feeds

```json
{
    "timestamp": 1706234567,
    "feeds": {
        "feodotracker": {
            "addresses": [167772160, 167772161, 167772162],
            "networks": [
                [167772160, 167772191],
                [184549376, 184549631]
            ]
        },
        "urlhaus": {
            "addresses": [3232235777, 3232235778],
            "networks": [[3232235776, 3232235855]]
        }
    }
}
```

**Fields**:

- `timestamp`: Unix timestamp of last update
- `feeds`: Object where keys are feed names
    - `addresses`: Sorted array of individual IPs as integers
    - `networks`: Sorted array of [start, end] range pairs as integers

**Integer Conversion**:

- IPv4: `10.0.0.1` ‚Üí `167772161`
- IPv6: `2001:db8::1` ‚Üí `42540766411282592856903984951653826561`
- CIDR: `10.0.0.0/27` ‚Üí `[167772160, 167772191]` (network to broadcast)

## ‚öôÔ∏è aggregator.py

Downloads and processes all feeds in parallel, handling multiple formats and edge cases.

**Features**:

- Parallel downloads with ThreadPoolExecutor (10 workers)
- IPv4/IPv6 support with embedded address extraction
- CIDR range expansion to [start, end] pairs
- ASN resolution for datacenter and Tor networks
- Deduplication and sorting for binary search
- Regex-based parsing for diverse feed formats

**Special Handling**:

- `datacenter_asns`: Resolves ASN numbers to IP ranges via RIPE API
- `tor_onionoo`: Combines Tor relay list with known Tor ASNs
- IPv6 mapped addresses: Extracts embedded IPv4 (::ffff:192.0.2.1)
- 6to4 tunnels: Extracts IPv4 from 2002::/16 addresses

**Usage**:

```bash
python aggregator.py
```

**Output**: Creates/updates `blocklist.json` with all processed feeds and `datacenter_asns.json` with datacenter ASN list

## üêç Python Lookup Examples

### Basic Lookup

```python
import json
import ipaddress

with open("blocklist.json") as f:
    data = json.load(f)

def check_ip(ip_string, feeds):
    target = int(ipaddress.ip_address(ip_string))
    matches = []

    for name, list_data in feeds.items():
        if target in list_data["addresses"]:
            matches.append(name)
            continue

        for start, end in list_data["networks"]:
            if start <= target <= end:
                matches.append(name)
                break

    return matches

result = check_ip("10.0.0.1", data["feeds"])
print(result)
```

### Optimized Binary Search

```python
import json
import ipaddress
from bisect import bisect_left

with open("blocklist.json") as f:
    data = json.load(f)

def check_ip_fast(ip_string, feeds):
    target = int(ipaddress.ip_address(ip_string))
    matches = []

    for name, list_data in feeds.items():
        addresses = list_data["addresses"]
        index = bisect_left(addresses, target)
        if index < len(addresses) and addresses[index] == target:
            matches.append(name)
            continue

        for start, end in list_data["networks"]:
            if start <= target <= end:
                matches.append(name)
                break

    return matches

result = check_ip_fast("192.168.1.1", data["feeds"])
print(result)
```

### Batch Lookup

```python
import json
import ipaddress
from bisect import bisect_left

with open("blocklist.json") as f:
    data = json.load(f)

def check_batch(ip_list, feeds):
    results = {}

    for ip_string in ip_list:
        target = int(ipaddress.ip_address(ip_string))
        matches = []

        for name, list_data in feeds.items():
            addresses = list_data["addresses"]
            index = bisect_left(addresses, target)
            if index < len(addresses) and addresses[index] == target:
                matches.append(name)
                continue

            for start, end in list_data["networks"]:
                if start <= target <= end:
                    matches.append(name)
                    break

        results[ip_string] = matches

    return results

ips = ["10.0.0.1", "192.168.1.1", "8.8.8.8"]
results = check_batch(ips, data["feeds"])
for ip, feeds in results.items():
    print(f"{ip}: {feeds}")
```

### Datacenter ASN Lookup

```python
import json

def load_datacenter_asns(asn_file="datacenter_asns.json"):
    """Load datacenter ASNs into a set for O(1) lookups."""
    try:
        with open(asn_file) as f:
            return set(json.load(f))
    except Exception as e:
        print(f"Error loading ASNs: {e}")
        return set()

def is_datacenter_asn(asn, asns=None):
    """Check if ASN belongs to a datacenter."""
    if not asns:
        asns = load_datacenter_asns()
    return asn.replace("AS", "").strip() in asns

asns = load_datacenter_asns()
for asn in ["AS16509", "AS13335", "AS15169"]:
    result = "is" if is_datacenter_asn(asn, asns) else "is not"
    print(f"{asn} {result} a datacenter ASN")
```

### Reputation Scoring

```python
import json
import ipaddress
from bisect import bisect_left

with open("blocklist.json") as f:
    data = json.load(f)

with open("feeds.json") as f:
    feeds = json.load(f)

sources = {feed["name"]: feed for feed in feeds}

def check_ip_with_reputation(ip_string, feeds, sources):
    target = int(ipaddress.ip_address(ip_string))
    matches = []

    for name, list_data in feeds.items():
        addresses = list_data["addresses"]
        index = bisect_left(addresses, target)
        if index < len(addresses) and addresses[index] == target:
            matches.append(name)
            continue

        for start, end in list_data["networks"]:
            if start <= target <= end:
                matches.append(name)
                break

    if not matches:
        return {"ip": ip_string, "score": 0.0, "feeds": []}

    flags = {}
    scores = {
        "anonymizer": [], "attacks": [], "botnet": [],
        "compromised": [], "infrastructure": [], "malware": [], "spam": []
    }

    for list_name in matches:
        source = sources.get(list_name)
        if not source:
            continue

        for flag in source.get("flags", []):
            flags[flag] = True

        provider = source.get("provider_name")
        if provider:
            flags["vpn_provider"] = provider

        base_score = source.get("base_score", 0.5)
        for category in source.get("categories", []):
            if category in scores:
                scores[category].append(base_score)

    total = 0.0
    for category_scores in scores.values():
        if not category_scores:
            continue
        combined = 1.0
        for score in sorted(category_scores, reverse=True):
            combined *= 1.0 - score
        total += 1.0 - combined

    return {
        "ip": ip_string,
        "score": min(total / 1.5, 1.0),
        "feeds": matches,
        **flags
    }

result = check_ip_with_reputation("10.0.0.1", data["feeds"], sources)
print(json.dumps(result, indent=2))
```

## ‚ö° Performance Characteristics

**Dataset Statistics**:

- Total feeds: 127
- Individual IPs: 4.4M (4.4M IPv4, 5,655 IPv6)
- CIDR ranges: 4647K (4628K IPv4, 19K IPv6)
- Total entries: 9.1M
- File size: 60MB

**Lookup Complexity**:

- Individual IPs: 4.4M (4.4M IPv4, 5,655 IPv6)
- CIDR ranges: 4647K (4628K IPv4, 19K IPv6)
- Typical lookup: <1ms for 127 feeds with 9.1M entries

**Memory Usage**:

- Integer storage: 4 bytes per IPv4, 16 bytes per IPv6
- Range storage: 8 bytes per IPv4 range, 32 bytes per IPv6 range

## üí° Use Cases

- **API Rate Limiting**: Block known malicious IPs
- **Fraud Detection**: Flag VPN/proxy/datacenter traffic
- **Security Analytics**: Enrich logs with threat intelligence
- **Access Control**: Restrict Tor exit nodes or anonymizers
- **Compliance**: Block traffic from sanctioned networks

## üìú License

Copyright 2025 TN3W

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
